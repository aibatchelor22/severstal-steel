{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n#RLE functions from https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode/code\n\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nimport matplotlib.pyplot as plt\nimport os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nfrom numpy import fliplr, flipud\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.optimizers import Adam\nfrom keras.layers import Input, BatchNormalization\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nimport segmentation_models\n\n\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_HEIGHT = 256\nIMG_WIDTH = 1600\nIMG_CHANNELS = 3\nDEFECT_CLASSES = 4\nSCALE_FACTOR = 2\nSAMPLE_SIZE = 950\n\ntrain = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\nIMAGE_PATH = r\"../input/severstal-steel-defect-detection/train_images/\"\nTEST_IMAGE_PATH = r\"../input/severstal-steel-defect-detection/test_images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import images\nfrom skimage import color\nfrom skimage import io\n\n#import masks\nclass_indices = [[],[],[],[]]\nmulticlass_image_list = []\n\nfor ind in range(train.shape[0]):\n    #Check if multiple masks exist, if so, add to its own class\n    if train['EncodedPixels'][ind] != '':\n        current_file_name = train['ImageId'][ind]\n        if train[train['ImageId'] == current_file_name].shape[0] == 1:\n            class_indices[train['ClassId'][ind]-1].append(ind)\n        elif current_file_name not in multiclass_image_list:\n            multiclass_image_list.append(current_file_name)\n            \n            \n\n    \n    \nY_train = np.zeros((SAMPLE_SIZE*4, int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), int(DEFECT_CLASSES)), dtype=np.bool)\n\n\n#get a random sample from each class\nsample_set = []\nfor defect_type in range(4):\n    partial_sample_set = np.random.permutation(int(SAMPLE_SIZE/5))\n    for sample_index in partial_sample_set:\n        sample_set.append(class_indices[defect_type][sample_index])\n\n#Populate training data for the single class images\nn=0        \nfor ind in range(len(sample_set)):\n\n    img = rle2mask(train['EncodedPixels'][sample_set[ind]])\n    img = resize(img, (int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR)), mode='constant', preserve_range=True)\n    Y_train[n,:,:,(train['ClassId'][sample_set[ind]]-1)] = img\n    Y_train[n+1,:,:,(train['ClassId'][sample_set[ind]]-1)] = fliplr(img)\n    Y_train[n+2,:,:,(train['ClassId'][sample_set[ind]]-1)] = flipud(img)\n    Y_train[n+3,:,:,(train['ClassId'][sample_set[ind]]-1)] = fliplr(flipud(img))\n    n+=4\n    \n#Handle multiple mask instances\nmulticlass_samples = []\npartial_sample_set_indices = np.random.permutation(int(SAMPLE_SIZE/5))\nfor ind in partial_sample_set_indices:\n    multiclass_samples.append(multiclass_image_list[ind])\nfor current_file_name in multiclass_samples:\n    #make temporary dataframe corresponding to this image\n    df = train[train['ImageId'] == current_file_name]\n    df = df.reset_index(drop=True)\n    for ind in range(df.shape[0]):\n        #add each mask to an entry\n        img = rle2mask(df['EncodedPixels'][ind])\n        img = resize(img, (int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR)), mode='constant', preserve_range=True)\n        Y_train[n,:,:,(df['ClassId'][ind]-1)] = img\n        Y_train[n+1,:,:,(df['ClassId'][ind]-1)] = fliplr(img)\n        Y_train[n+2,:,:,(df['ClassId'][ind]-1)] = flipud(img)\n        Y_train[n+3,:,:,(df['ClassId'][ind]-1)] = fliplr(flipud(img))\n    n += 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.zeros((SAMPLE_SIZE*4, int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS), dtype=np.uint8)\n#Populate X_train for single class images\nn = 0\nfor ind in range(len(sample_set)):\n    #img = color.rgb2gray(io.imread(IMAGE_PATH + train['ImageId'][ind]))\n    img = imread(IMAGE_PATH + train['ImageId'][sample_set[ind]])\n    img = resize(img, (int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS), mode='constant', preserve_range=True)\n    X_train[n,:,:,:] = img\n    X_train[n+1,:,:,:] = fliplr(img)\n    X_train[n+2,:,:,:] = flipud(img)\n    X_train[n+3,:,:,:] = fliplr(flipud(img))\n    n += 4\n    \n#Populate X_train for multiclass images\nfor file_name in multiclass_samples:\n    img = imread(IMAGE_PATH + file_name)\n    #img = color.rgb2gray(io.imread(IMAGE_PATH + file_name))\n    img = resize(img, (int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS), mode='constant', preserve_range=True)\n    X_train[n,:,:,:] = img\n    X_train[n+1,:,:,:] = fliplr(img)\n    X_train[n+2,:,:,:] = flipud(img)\n    X_train[n+3,:,:,:] = fliplr(flipud(img))\n    n += 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_loss(y_true, y_pred):    \n    return (1-dice_coef(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.2) (c1)\nc1 = BatchNormalization()(c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\nc1 = BatchNormalization()(c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.2) (c2)\nc2 = BatchNormalization()(c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\nc2 = BatchNormalization()(c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.3) (c3)\nc3 = BatchNormalization()(c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\nc3 = BatchNormalization()(c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.3) (c4)\nc4 = BatchNormalization()(c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\nc4 = BatchNormalization()(c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = BatchNormalization()(c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nu6 = BatchNormalization()(u6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.3) (c6)\nc6 = BatchNormalization()(c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\nc6 = BatchNormalization()(c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nu7 = BatchNormalization()(u7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = BatchNormalization()(c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nu8 = BatchNormalization()(u8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.3) (c8)\nc8 = BatchNormalization()(c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\nc8 = BatchNormalization()(c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nu9 = BatchNormalization()(u9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.2) (c9)\nc9 = BatchNormalization()(c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\nc9 = BatchNormalization()(c9)\n\noutputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nadamcustom = Adam(lr=0.005)\nmodel.compile(optimizer=adamcustom, loss=[dice_loss], metrics=[dice_coef])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model\nearlystopper = EarlyStopping(patience=5, verbose=1)\n#checkpointer = ModelCheckpoint('../input/severstal-steel-defect-detection/severstal_unetmodel', verbose=1, save_best_only=True\nmodel.fit(X_train, Y_train, validation_split=0.1, shuffle=True, batch_size=250, epochs=100,\n                    callbacks=[earlystopper])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get test data\ntestfiles = next(os.walk(TEST_IMAGE_PATH))[2]\nX_test = np.zeros((len(testfiles), int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), int(IMG_CHANNELS)), dtype=np.uint8)\n\nn = 0\nfor file in testfiles:\n  \n    #img = color.rgb2gray(io.imread(TEST_IMAGE_PATH + file))[:,:]\n    img = imread(TEST_IMAGE_PATH + file)\n    img = resize(img, (IMG_HEIGHT/SCALE_FACTOR, IMG_WIDTH/SCALE_FACTOR, IMG_CHANNELS), mode='constant', preserve_range=True)\n    X_test[n,:,:,:] = img\n    n += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_list = []\nfor n in range(len(testfiles)):\n    preds_test = model.predict(X_test[n:n+1,:,:,:])\n\n    # Threshold predictions\n    #preds_test_t = (preds_test > 0.5).astype(np.uint8)\n    #find which mask has the most non-zero data\n    for m in range(4):\n        img = preds_test[0,:,:,m]\n        #resize mask to original size\n        img = resize(img, (256, 1600), mode='constant', preserve_range=True)\n        img = (img > 0.4).astype(np.uint8)\n        #encode results and put in dataframe\n        encoded_entry = mask2rle(img)\n        row = [testfiles[n] + '_' + str(m+1), encoded_entry]\n        submission_list.append(row)\n    if n % 1000 == 0:\n        print('Saving entry', n)\n    \n#create submission file\nsubmission_data = pd.DataFrame(submission_list, columns=['ImageId_ClassId','EncodedPixels'])\nsubmission_data = submission_data.fillna('')\nsubmission_data.to_csv('./submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adamcustom = Adam(lr=0.005)\nmodel1 = segmentation_models.Unet('resnet34', encoder_weights='imagenet', input_shape=(int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS), encoder_freeze=True, classes=4, activation='sigmoid')\nmodel2 = segmentation_models.Unet('inceptionv3', encoder_weights='imagenet', input_shape=(int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS), encoder_freeze=True, classes=4, activation='sigmoid')\nmodel3 = segmentation_models.Unet('densenet121', encoder_weights='imagenet', input_shape=(int(IMG_HEIGHT/SCALE_FACTOR), int(IMG_WIDTH/SCALE_FACTOR), IMG_CHANNELS), encoder_freeze=True, classes=4, activation='sigmoid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.compile('Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nmodel1.compile('Adam', loss=[dice_loss], metrics=[dice_coef])\nmodel2.compile('Adam', loss=[dice_loss], metrics=[dice_coef])\nmodel3.compile('Adam', loss=[dice_loss], metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\nmodel1.fit(X_train, Y_train, validation_split=0.1, shuffle=True, batch_size=50, epochs=15,\n                    callbacks=[earlystopper])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\nmodel2.fit(X_train, Y_train, validation_split=0.1, shuffle=True, batch_size=50, epochs=15,\n                    callbacks=[earlystopper])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\nmodel3.fit(X_train, Y_train, validation_split=0.1, shuffle=True, batch_size=20, epochs=15,\n                    callbacks=[earlystopper])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_list = []\nfor n in range(len(testfiles)):\n    preds_test1 = model1.predict(X_test[n:n+1,:,:,:])\n    preds_test2 = model2.predict(X_test[n:n+1,:,:,:])\n    preds_test3 = model3.predict(X_test[n:n+1,:,:,:])\n\n    # Threshold predictions\n    #preds_test_t = (preds_test > 0.5).astype(np.uint8)\n    #find which mask has the most non-zero data\n    for m in range(4):\n        img1 = preds_test1[0,:,:,m]\n        img2 = preds_test2[0,:,:,m]\n        img3 = preds_test3[0,:,:,m]\n        img = np.mean([img1,img2,img3], axis=0)\n        #resize mask to original size\n        img = resize(img, (256, 1600), mode='constant', preserve_range=True)\n        img = (img > 0.5).astype(np.uint8)\n        #encode results and put in dataframe\n        encoded_entry = mask2rle(img)\n        row = [testfiles[n] + '_' + str(m+1), encoded_entry]\n        submission_list.append(row)\n    if n % 1000 == 0:\n        print('Saving entry', n)\n    \n#create submission file\nsubmission_data = pd.DataFrame(submission_list, columns=['ImageId_ClassId','EncodedPixels'])\nsubmission_data = submission_data.fillna('')\nsubmission_data.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}